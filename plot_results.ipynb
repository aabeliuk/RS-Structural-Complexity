{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System Sampling Experiments - Results Analysis\n",
    "\n",
    "This notebook provides comprehensive visualization and analysis of the sampling experiment results.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We analyze how different sampling strategies affect recommendation system performance across:\n",
    "- **12 Datasets**: Amazon Health, Grocery, book-crossing, lastfm, ModCloth, pinterest, RateBeer, steam, yelp2022, jester, Behance, mind\n",
    "- **3 Algorithms**: LightGCN, BPR, NeuMF\n",
    "- **4 Sampling Strategies**: difficult, random, difficult_inverse (easiest), temporal\n",
    "- **10 Sampling Rates**: 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%\n",
    "- **3 Metrics**: Precision@10, NDCG@10, MAP@10\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. Which sampling strategy minimizes performance loss with limited data?\n",
    "2. At what sampling rate does performance plateau?\n",
    "3. Are difficult ratings more informative than random?\n",
    "4. Do results generalize across datasets and algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing plotly for interactive visualizations\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"Plotly available: Interactive plots enabled\")\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"Plotly not available: Skipping interactive plots\")\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Figure sizes\n",
    "FIGSIZE_SINGLE = (10, 6)\n",
    "FIGSIZE_TRIPLE = (15, 5)\n",
    "FIGSIZE_GRID = (12, 10)\n",
    "\n",
    "# Color scheme (consistent with run_experiments.py)\n",
    "COLORS = {\n",
    "    'difficult': '#E74C3C',           # Red\n",
    "    'random': '#3498DB',              # Blue\n",
    "    'difficult_inverse': '#2ECC71',   # Green (easiest)\n",
    "    'temporal': '#F77F00'             # Orange\n",
    "}\n",
    "\n",
    "# Font sizes\n",
    "TITLE_SIZE = 14\n",
    "LABEL_SIZE = 12\n",
    "TICK_SIZE = 10\n",
    "\n",
    "# Directory paths\n",
    "RESULTS_DIR = Path('results')\n",
    "PLOTS_DIR = Path('plots')\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggregated results\n",
    "csv_path = RESULTS_DIR / 'all_results_summary.csv'\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print(f\"ERROR: {csv_path} not found!\")\n",
    "    print(f\"Please ensure experiments have been run and results are in {RESULTS_DIR}/\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded data from: {csv_path}\")\n",
    "    print(f\"Data shape: {df.shape[0]} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data overview\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA COMPLETENESS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nUnique values per dimension:\")\n",
    "print(f\"Datasets: {df['dataset'].nunique()} - {sorted(df['dataset'].unique())}\")\n",
    "print(f\"Algorithms: {df['algorithm'].nunique()} - {sorted(df['algorithm'].unique())}\")\n",
    "print(f\"Strategies: {df['strategy'].nunique()} - {sorted(df['strategy'].unique())}\")\n",
    "print(f\"Sampling Rates: {df['sampling_rate'].nunique()} - {sorted(df['sampling_rate'].unique())}\")\n",
    "\n",
    "# Expected vs actual experiments\n",
    "expected_datasets = 12\n",
    "expected_algorithms = 3\n",
    "expected_strategies = 4\n",
    "expected_rates = 10\n",
    "\n",
    "expected_total = expected_datasets * expected_algorithms * expected_strategies * expected_rates\n",
    "actual_total = len(df)\n",
    "\n",
    "print(f\"\\nExpected total experiments: {expected_total}\")\n",
    "print(f\"Actual experiments: {actual_total}\")\n",
    "print(f\"Completion: {actual_total/expected_total*100:.1f}%\")\n",
    "print(f\"Missing: {expected_total - actual_total} experiments\")\n",
    "\n",
    "# Count by dataset-algorithm combination\n",
    "print(\"\\nExperiments per dataset-algorithm combination:\")\n",
    "pivot = df.groupby(['dataset', 'algorithm']).size().unstack(fill_value=0)\n",
    "display(pivot)\n",
    "\n",
    "# Missing combinations\n",
    "print(\"\\nMissing dataset-algorithm combinations:\")\n",
    "all_datasets = ['Amazon_Health_and_Personal_Care', 'Amazon_Grocery_and_Gourmet_Food', \n",
    "                'book-crossing', 'lastfm', 'ModCloth', 'pinterest', 'RateBeer', \n",
    "                'steam', 'yelp2022', 'jester', 'Behance', 'mind']\n",
    "all_algorithms = ['LightGCN', 'BPR', 'NeuMF']\n",
    "\n",
    "missing_combos = []\n",
    "for dataset in all_datasets:\n",
    "    for algorithm in all_algorithms:\n",
    "        if len(df[(df['dataset'] == dataset) & (df['algorithm'] == algorithm)]) == 0:\n",
    "            missing_combos.append(f\"{dataset} - {algorithm}\")\n",
    "\n",
    "if missing_combos:\n",
    "    print(f\"Found {len(missing_combos)} missing combinations:\")\n",
    "    for combo in missing_combos[:10]:  # Show first 10\n",
    "        print(f\"  - {combo}\")\n",
    "    if len(missing_combos) > 10:\n",
    "        print(f\"  ... and {len(missing_combos) - 10} more\")\n",
    "else:\n",
    "    print(\"All dataset-algorithm combinations present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by metric\n",
    "print(\"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS BY METRIC\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metrics = ['precision', 'ndcg', 'map']\n",
    "\n",
    "for metric in metrics:\n",
    "    if metric in df.columns:\n",
    "        print(f\"\\n{metric.upper()}@10:\")\n",
    "        print(f\"  Mean: {df[metric].mean():.4f}\")\n",
    "        print(f\"  Std:  {df[metric].std():.4f}\")\n",
    "        print(f\"  Min:  {df[metric].min():.4f}\")\n",
    "        print(f\"  Max:  {df[metric].max():.4f}\")\n",
    "        \n",
    "        # By strategy\n",
    "        print(f\"\\n  By Strategy:\")\n",
    "        strategy_stats = df.groupby('strategy')[metric].agg(['mean', 'std', 'count'])\n",
    "        display(strategy_stats)\n",
    "\n",
    "# RPA statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RELATIVE PERFORMANCE ANALYSIS (RPA) STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rpa_metrics = ['precision_rpa', 'ndcg_rpa', 'map_rpa']\n",
    "\n",
    "for metric in rpa_metrics:\n",
    "    if metric in df.columns:\n",
    "        # Filter out 100% sampling (RPA = 0 by definition)\n",
    "        df_filtered = df[df['sampling_rate'] != 100]\n",
    "        \n",
    "        print(f\"\\n{metric.upper()} (% change vs 100% baseline):\")\n",
    "        print(f\"  Mean: {df_filtered[metric].mean():.2f}%\")\n",
    "        print(f\"  Std:  {df_filtered[metric].std():.2f}%\")\n",
    "        print(f\"  Min:  {df_filtered[metric].min():.2f}%\")\n",
    "        print(f\"  Max:  {df_filtered[metric].max():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Individual Performance Plots\n",
    "\n",
    "This section recreates the metric and RPA plots for each dataset-algorithm combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Filter data\n",
    "def get_data(df, dataset=None, algorithm=None, strategy=None, sampling_rate=None):\n",
    "    \"\"\"\n",
    "    Filter dataframe by criteria.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset\n",
    "    dataset : str, optional\n",
    "        Filter by dataset name\n",
    "    algorithm : str, optional\n",
    "        Filter by algorithm\n",
    "    strategy : str, optional\n",
    "        Filter by sampling strategy\n",
    "    sampling_rate : int, optional\n",
    "        Filter by sampling rate\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Filtered data\n",
    "    \"\"\"\n",
    "    filtered = df.copy()\n",
    "    if dataset:\n",
    "        filtered = filtered[filtered['dataset'] == dataset]\n",
    "    if algorithm:\n",
    "        filtered = filtered[filtered['algorithm'] == algorithm]\n",
    "    if strategy:\n",
    "        filtered = filtered[filtered['strategy'] == strategy]\n",
    "    if sampling_rate is not None:\n",
    "        filtered = filtered[filtered['sampling_rate'] == sampling_rate]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Plot metrics for one dataset-algorithm\n",
    "def plot_metric_comparison(df, dataset, algorithm, save=True):\n",
    "    \"\"\"\n",
    "    Generate metric comparison plot (Precision, NDCG, MAP) for one dataset-algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset\n",
    "    dataset : str\n",
    "        Dataset name\n",
    "    algorithm : str\n",
    "        Algorithm name\n",
    "    save : bool, optional\n",
    "        Whether to save the plot\n",
    "    \"\"\"\n",
    "    # Filter data\n",
    "    data = get_data(df, dataset=dataset, algorithm=algorithm)\n",
    "    \n",
    "    # Check if enough data\n",
    "    if len(data) < 3:\n",
    "        print(f\"Insufficient data for {dataset} - {algorithm} (only {len(data)} rows)\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "    metrics = ['precision', 'ndcg', 'map']\n",
    "    metric_labels = ['Precision@10', 'NDCG@10', 'MAP@10']\n",
    "    \n",
    "    for ax, metric, label in zip(axes, metrics, metric_labels):\n",
    "        for strategy in data['strategy'].unique():\n",
    "            strategy_data = data[data['strategy'] == strategy].sort_values('sampling_rate')\n",
    "            \n",
    "            # Only plot if data exists\n",
    "            if len(strategy_data) > 0:\n",
    "                ax.plot(strategy_data['sampling_rate'], strategy_data[metric],\n",
    "                       marker='o', label=strategy, color=COLORS.get(strategy, 'gray'),\n",
    "                       linewidth=2, markersize=6)\n",
    "        \n",
    "        ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "        ax.set_ylabel(label, fontsize=LABEL_SIZE)\n",
    "        ax.set_title(f'{label}', fontsize=TITLE_SIZE)\n",
    "        ax.legend(fontsize=TICK_SIZE)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(f'{dataset} - {algorithm}', fontsize=TITLE_SIZE + 2, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if requested\n",
    "    if save:\n",
    "        filename = PLOTS_DIR / f'{dataset}_{algorithm}_metrics.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {filename}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Plot RPA for one dataset-algorithm\n",
    "def plot_rpa_comparison(df, dataset, algorithm, save=True):\n",
    "    \"\"\"\n",
    "    Generate RPA comparison plot for one dataset-algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset\n",
    "    dataset : str\n",
    "        Dataset name\n",
    "    algorithm : str\n",
    "        Algorithm name\n",
    "    save : bool, optional\n",
    "        Whether to save the plot\n",
    "    \"\"\"\n",
    "    # Filter data (exclude 100% sampling for RPA plots)\n",
    "    data = get_data(df, dataset=dataset, algorithm=algorithm)\n",
    "    data = data[data['sampling_rate'] != 100]\n",
    "    \n",
    "    # Check if enough data\n",
    "    if len(data) < 3:\n",
    "        print(f\"Insufficient data for {dataset} - {algorithm} RPA (only {len(data)} rows)\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "    rpa_metrics = ['precision_rpa', 'ndcg_rpa', 'map_rpa']\n",
    "    metric_labels = ['Precision@10 RPA', 'NDCG@10 RPA', 'MAP@10 RPA']\n",
    "    \n",
    "    for ax, metric, label in zip(axes, rpa_metrics, metric_labels):\n",
    "        for strategy in data['strategy'].unique():\n",
    "            strategy_data = data[data['strategy'] == strategy].sort_values('sampling_rate')\n",
    "            \n",
    "            # Only plot if data exists\n",
    "            if len(strategy_data) > 0:\n",
    "                ax.plot(strategy_data['sampling_rate'], strategy_data[metric],\n",
    "                       marker='o', label=strategy, color=COLORS.get(strategy, 'gray'),\n",
    "                       linewidth=2, markersize=6)\n",
    "        \n",
    "        # Add horizontal line at 0%\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "        ax.set_ylabel('% Change vs 100%', fontsize=LABEL_SIZE)\n",
    "        ax.set_title(f'{label}', fontsize=TITLE_SIZE)\n",
    "        ax.legend(fontsize=TICK_SIZE)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle(f'{dataset} - {algorithm} (RPA)', fontsize=TITLE_SIZE + 2, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if requested\n",
    "    if save:\n",
    "        filename = PLOTS_DIR / f'{dataset}_{algorithm}_rpa.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {filename}\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots for all dataset-algorithm combinations with data\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATING INDIVIDUAL PLOTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "combinations = df.groupby(['dataset', 'algorithm']).size().reset_index()[['dataset', 'algorithm']]\n",
    "\n",
    "print(f\"\\nFound {len(combinations)} dataset-algorithm combinations with data\\n\")\n",
    "\n",
    "for idx, row in combinations.iterrows():\n",
    "    dataset = row['dataset']\n",
    "    algorithm = row['algorithm']\n",
    "    \n",
    "    print(f\"\\n[{idx+1}/{len(combinations)}] Plotting: {dataset} - {algorithm}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Metric plots\n",
    "    print(\"Metrics plot:\")\n",
    "    plot_metric_comparison(df, dataset, algorithm, save=True)\n",
    "    \n",
    "    # RPA plots\n",
    "    print(\"\\nRPA plot:\")\n",
    "    plot_rpa_comparison(df, dataset, algorithm, save=True)\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INDIVIDUAL PLOTS COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Aggregated Analysis\n",
    "\n",
    "This section combines results across datasets and algorithms to identify general trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average performance by strategy across all datasets\n",
    "print(\"=\" * 80)\n",
    "print(\"AVERAGE PERFORMANCE BY STRATEGY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Group by strategy and sampling_rate, calculate mean and std\n",
    "strategy_avg = df.groupby(['strategy', 'sampling_rate']).agg({\n",
    "    'ndcg': ['mean', 'std'],\n",
    "    'precision': ['mean', 'std'],\n",
    "    'map': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Plot average NDCG@10 by strategy\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "\n",
    "for strategy in df['strategy'].unique():\n",
    "    strategy_data = strategy_avg[strategy_avg['strategy'] == strategy].sort_values('sampling_rate')\n",
    "    \n",
    "    if len(strategy_data) > 0:\n",
    "        means = strategy_data['ndcg']['mean'].values\n",
    "        stds = strategy_data['ndcg']['std'].values\n",
    "        rates = strategy_data['sampling_rate'].values\n",
    "        \n",
    "        # Plot with error bars\n",
    "        ax.plot(rates, means, marker='o', label=strategy, \n",
    "               color=COLORS.get(strategy, 'gray'), linewidth=2, markersize=6)\n",
    "        ax.fill_between(rates, means - stds, means + stds, \n",
    "                       alpha=0.2, color=COLORS.get(strategy, 'gray'))\n",
    "\n",
    "ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "ax.set_ylabel('Average NDCG@10', fontsize=LABEL_SIZE)\n",
    "ax.set_title('Average NDCG@10 Across All Datasets', fontsize=TITLE_SIZE)\n",
    "ax.legend(fontsize=TICK_SIZE)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.tick_params(labelsize=TICK_SIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'aggregated_ndcg_by_strategy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAverage NDCG@10 statistics by strategy:\")\n",
    "display(df.groupby('strategy')['ndcg'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Best NDCG@10 at 50% sampling\n",
    "print(\"=\" * 80)\n",
    "print(\"PERFORMANCE HEATMAP AT 50% SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter for 50% sampling rate\n",
    "df_50 = df[df['sampling_rate'] == 50].copy()\n",
    "\n",
    "if len(df_50) > 0:\n",
    "    # For each dataset-algorithm, find the best strategy\n",
    "    best_ndcg = df_50.groupby(['dataset', 'algorithm', 'strategy'])['ndcg'].mean().reset_index()\n",
    "    \n",
    "    # Pivot to get dataset x algorithm matrix with best NDCG\n",
    "    pivot_best = best_ndcg.groupby(['dataset', 'algorithm'])['ndcg'].max().unstack(fill_value=0)\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_GRID)\n",
    "    sns.heatmap(pivot_best, annot=True, fmt='.4f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Best NDCG@10'}, ax=ax)\n",
    "    ax.set_title('Best NDCG@10 at 50% Sampling\\n(across all strategies)', fontsize=TITLE_SIZE)\n",
    "    ax.set_xlabel('Algorithm', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel('Dataset', fontsize=LABEL_SIZE)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'heatmap_50pct_sampling.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nBest NDCG@10 values at 50% sampling:\")\n",
    "    display(pivot_best)\n",
    "else:\n",
    "    print(\"No data available for 50% sampling rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy effectiveness comparison (Average RPA)\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATEGY EFFECTIVENESS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter out 100% sampling\n",
    "df_rpa = df[df['sampling_rate'] != 100].copy()\n",
    "\n",
    "if len(df_rpa) > 0:\n",
    "    # Key sampling rates for comparison\n",
    "    key_rates = [30, 50, 70]\n",
    "    available_rates = [r for r in key_rates if r in df_rpa['sampling_rate'].unique()]\n",
    "    \n",
    "    if available_rates:\n",
    "        df_key = df_rpa[df_rpa['sampling_rate'].isin(available_rates)]\n",
    "        \n",
    "        # Calculate average RPA by strategy and sampling rate\n",
    "        rpa_avg = df_key.groupby(['strategy', 'sampling_rate'])['ndcg_rpa'].mean().reset_index()\n",
    "        \n",
    "        # Bar chart\n",
    "        fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "        \n",
    "        x = np.arange(len(available_rates))\n",
    "        width = 0.2\n",
    "        \n",
    "        strategies = sorted(df['strategy'].unique())\n",
    "        for i, strategy in enumerate(strategies):\n",
    "            strategy_data = rpa_avg[rpa_avg['strategy'] == strategy]\n",
    "            values = [strategy_data[strategy_data['sampling_rate'] == rate]['ndcg_rpa'].values[0] \n",
    "                     if len(strategy_data[strategy_data['sampling_rate'] == rate]) > 0 else 0\n",
    "                     for rate in available_rates]\n",
    "            \n",
    "            ax.bar(x + i*width, values, width, label=strategy, \n",
    "                  color=COLORS.get(strategy, 'gray'))\n",
    "        \n",
    "        ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "        ax.set_ylabel('Average NDCG RPA (%)', fontsize=LABEL_SIZE)\n",
    "        ax.set_title('Average Performance Loss by Strategy', fontsize=TITLE_SIZE)\n",
    "        ax.set_xticks(x + width * (len(strategies)-1) / 2)\n",
    "        ax.set_xticklabels(available_rates)\n",
    "        ax.legend(fontsize=TICK_SIZE)\n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PLOTS_DIR / 'strategy_rpa_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nAverage NDCG RPA by strategy:\")\n",
    "        display(df_rpa.groupby('strategy')['ndcg_rpa'].describe())\n",
    "    else:\n",
    "        print(f\"None of the key rates {key_rates} available in data\")\n",
    "else:\n",
    "    print(\"No RPA data available (all sampling rates are 100%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated RPA plot (similar to run_experiments.py)\n",
    "print(\"=\" * 80)\n",
    "print(\"AGGREGATED RPA PLOT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(df_rpa) > 0:\n",
    "    # Calculate average RPA across all datasets and algorithms\n",
    "    aggregated_rpa = df_rpa.groupby(['strategy', 'sampling_rate']).agg({\n",
    "        'ndcg_rpa': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "    \n",
    "    for strategy in df['strategy'].unique():\n",
    "        strategy_data = aggregated_rpa[aggregated_rpa['strategy'] == strategy].sort_values('sampling_rate')\n",
    "        \n",
    "        if len(strategy_data) > 0:\n",
    "            rates = strategy_data['sampling_rate'].values\n",
    "            means = strategy_data['ndcg_rpa']['mean'].values\n",
    "            stds = strategy_data['ndcg_rpa']['std'].values\n",
    "            \n",
    "            ax.plot(rates, means, marker='o', label=strategy,\n",
    "                   color=COLORS.get(strategy, 'gray'), linewidth=2, markersize=6)\n",
    "            ax.fill_between(rates, means - stds, means + stds,\n",
    "                           alpha=0.2, color=COLORS.get(strategy, 'gray'))\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Baseline (100%)')\n",
    "    ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel('Average NDCG RPA (%)', fontsize=LABEL_SIZE)\n",
    "    ax.set_title('Aggregated RPA: Average Performance Loss Across All Experiments', fontsize=TITLE_SIZE)\n",
    "    ax.legend(fontsize=TICK_SIZE)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'aggregated_rpa.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No RPA data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Statistical Analysis\n",
    "\n",
    "Deeper statistical insights into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of RPA by strategy\n",
    "print(\"=\" * 80)\n",
    "print(\"RPA DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(df_rpa) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "    rpa_metrics = ['precision_rpa', 'ndcg_rpa', 'map_rpa']\n",
    "    metric_labels = ['Precision RPA', 'NDCG RPA', 'MAP RPA']\n",
    "    \n",
    "    for ax, metric, label in zip(axes, rpa_metrics, metric_labels):\n",
    "        # Box plot\n",
    "        data_for_plot = [df_rpa[df_rpa['strategy'] == s][metric].dropna() \n",
    "                        for s in sorted(df['strategy'].unique())]\n",
    "        \n",
    "        bp = ax.boxplot(data_for_plot, labels=sorted(df['strategy'].unique()),\n",
    "                       patch_artist=True)\n",
    "        \n",
    "        # Color boxes\n",
    "        for patch, strategy in zip(bp['boxes'], sorted(df['strategy'].unique())):\n",
    "            patch.set_facecolor(COLORS.get(strategy, 'gray'))\n",
    "            patch.set_alpha(0.6)\n",
    "        \n",
    "        ax.axhline(y=0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        ax.set_ylabel(f'{label} (%)', fontsize=LABEL_SIZE)\n",
    "        ax.set_title(f'{label} Distribution', fontsize=TITLE_SIZE)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.tick_params(labelsize=TICK_SIZE)\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'rpa_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No RPA data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis between metrics\n",
    "print(\"=\" * 80)\n",
    "print(\"METRIC CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Correlation matrix\n",
    "metrics_for_corr = ['precision', 'ndcg', 'map']\n",
    "corr_matrix = df[metrics_for_corr].corr()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "display(corr_matrix)\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=ax, vmin=-1, vmax=1)\n",
    "ax.set_title('Metric Correlation Matrix', fontsize=TITLE_SIZE)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'metric_correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "pairs = [('precision', 'ndcg'), ('precision', 'map'), ('ndcg', 'map')]\n",
    "\n",
    "for ax, (metric1, metric2) in zip(axes, pairs):\n",
    "    for strategy in df['strategy'].unique():\n",
    "        strategy_data = df[df['strategy'] == strategy]\n",
    "        ax.scatter(strategy_data[metric1], strategy_data[metric2],\n",
    "                  alpha=0.6, label=strategy, color=COLORS.get(strategy, 'gray'))\n",
    "    \n",
    "    ax.set_xlabel(f'{metric1.upper()}@10', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel(f'{metric2.upper()}@10', fontsize=LABEL_SIZE)\n",
    "    ax.set_title(f'{metric1.upper()} vs {metric2.upper()}', fontsize=TITLE_SIZE)\n",
    "    ax.legend(fontsize=TICK_SIZE-2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'metric_scatter_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling efficiency analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLING EFFICIENCY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each strategy, find the sampling rate where performance plateaus\n",
    "# (defined as RPA > -5%, i.e., within 5% of 100% baseline)\n",
    "\n",
    "if len(df_rpa) > 0:\n",
    "    print(\"\\nSampling rate where RPA > -5% (within 5% of baseline):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    plateau_threshold = -5.0\n",
    "    \n",
    "    for strategy in sorted(df['strategy'].unique()):\n",
    "        strategy_data = df_rpa[df_rpa['strategy'] == strategy].sort_values('sampling_rate')\n",
    "        \n",
    "        # Find minimum sampling rate where NDCG RPA > threshold\n",
    "        plateau_data = strategy_data[strategy_data['ndcg_rpa'] > plateau_threshold]\n",
    "        \n",
    "        if len(plateau_data) > 0:\n",
    "            min_rate = plateau_data['sampling_rate'].min()\n",
    "            print(f\"{strategy:20s}: {min_rate:3.0f}%\")\n",
    "        else:\n",
    "            print(f\"{strategy:20s}: Never reaches plateau (all < {plateau_threshold}%)\")\n",
    "    \n",
    "    # Marginal loss analysis\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MARGINAL LOSS PER 10% DATA REDUCTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for strategy in sorted(df['strategy'].unique()):\n",
    "        strategy_data = df[df['strategy'] == strategy].sort_values('sampling_rate')\n",
    "        \n",
    "        print(f\"\\n{strategy}:\")\n",
    "        \n",
    "        # Calculate marginal loss between consecutive sampling rates\n",
    "        for i in range(len(strategy_data) - 1):\n",
    "            rate1 = strategy_data.iloc[i]['sampling_rate']\n",
    "            rate2 = strategy_data.iloc[i+1]['sampling_rate']\n",
    "            ndcg1 = strategy_data.iloc[i]['ndcg']\n",
    "            ndcg2 = strategy_data.iloc[i+1]['ndcg']\n",
    "            \n",
    "            rate_diff = rate2 - rate1\n",
    "            ndcg_diff = ndcg2 - ndcg1\n",
    "            \n",
    "            # Normalize to per-10% change\n",
    "            ndcg_diff_normalized = ndcg_diff * (10.0 / rate_diff) if rate_diff > 0 else 0\n",
    "            \n",
    "            print(f\"  {rate1:.0f}% → {rate2:.0f}%: ΔNDCG = {ndcg_diff_normalized:+.4f} per 10%\")\n",
    "else:\n",
    "    print(\"No RPA data available for efficiency analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Comparative Analysis\n",
    "\n",
    "Direct comparisons across algorithms, datasets, and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm comparison\n",
    "print(\"=\" * 80)\n",
    "print(\"ALGORITHM COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Average performance by algorithm\n",
    "algo_avg = df.groupby('algorithm')[['precision', 'ndcg', 'map']].mean()\n",
    "\n",
    "print(\"\\nAverage metrics by algorithm:\")\n",
    "display(algo_avg)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=FIGSIZE_TRIPLE)\n",
    "metrics = ['precision', 'ndcg', 'map']\n",
    "metric_labels = ['Precision@10', 'NDCG@10', 'MAP@10']\n",
    "\n",
    "for ax, metric, label in zip(axes, metrics, metric_labels):\n",
    "    # Group by algorithm and sampling rate\n",
    "    for algorithm in sorted(df['algorithm'].unique()):\n",
    "        algo_data = df[df['algorithm'] == algorithm].groupby('sampling_rate')[metric].mean()\n",
    "        ax.plot(algo_data.index, algo_data.values, marker='o', label=algorithm, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "    ax.set_ylabel(label, fontsize=LABEL_SIZE)\n",
    "    ax.set_title(f'{label} by Algorithm', fontsize=TITLE_SIZE)\n",
    "    ax.legend(fontsize=TICK_SIZE)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'algorithm_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset characteristics\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET CHARACTERISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Performance at 100% (baseline predictability)\n",
    "df_100 = df[df['sampling_rate'] == 100].copy()\n",
    "\n",
    "if len(df_100) > 0:\n",
    "    dataset_baseline = df_100.groupby('dataset')['ndcg'].mean().sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\nDataset ranking by NDCG@10 at 100% sampling:\")\n",
    "    print(\"(Higher = more predictable)\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, (dataset, ndcg) in enumerate(dataset_baseline.items(), 1):\n",
    "        print(f\"{i:2d}. {dataset:40s}: {ndcg:.4f}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "    ax.barh(range(len(dataset_baseline)), dataset_baseline.values)\n",
    "    ax.set_yticks(range(len(dataset_baseline)))\n",
    "    ax.set_yticklabels(dataset_baseline.index)\n",
    "    ax.set_xlabel('NDCG@10 at 100% Sampling', fontsize=LABEL_SIZE)\n",
    "    ax.set_title('Dataset Predictability Ranking', fontsize=TITLE_SIZE)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'dataset_ranking.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No 100% sampling data available for baseline comparison\")\n",
    "\n",
    "# Performance loss sensitivity\n",
    "if len(df_rpa) > 0:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DATASET SENSITIVITY TO SAMPLING\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nAverage NDCG RPA by dataset (lower is better):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    dataset_sensitivity = df_rpa.groupby('dataset')['ndcg_rpa'].mean().sort_values()\n",
    "    \n",
    "    for i, (dataset, rpa) in enumerate(dataset_sensitivity.items(), 1):\n",
    "        print(f\"{i:2d}. {dataset:40s}: {rpa:+.2f}%\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "    colors_bar = ['green' if x > -10 else 'orange' if x > -20 else 'red' \n",
    "                  for x in dataset_sensitivity.values]\n",
    "    ax.barh(range(len(dataset_sensitivity)), dataset_sensitivity.values, color=colors_bar, alpha=0.7)\n",
    "    ax.set_yticks(range(len(dataset_sensitivity)))\n",
    "    ax.set_yticklabels(dataset_sensitivity.index)\n",
    "    ax.set_xlabel('Average NDCG RPA (%)', fontsize=LABEL_SIZE)\n",
    "    ax.set_title('Dataset Sensitivity to Sampling\\n(Lower = Less Sensitive)', fontsize=TITLE_SIZE)\n",
    "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'dataset_sensitivity.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy rankings\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATEGY RANKINGS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall average performance by strategy\n",
    "strategy_ranking = df.groupby('strategy')[['precision', 'ndcg', 'map']].mean().sort_values('ndcg', ascending=False)\n",
    "\n",
    "print(\"\\nOverall strategy ranking (by average NDCG@10):\")\n",
    "display(strategy_ranking)\n",
    "\n",
    "# Win-rate analysis: How often does each strategy perform best?\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STRATEGY WIN-RATE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each dataset-algorithm-sampling_rate combination, find the best strategy\n",
    "grouped = df.groupby(['dataset', 'algorithm', 'sampling_rate'])\n",
    "wins = {strategy: 0 for strategy in df['strategy'].unique()}\n",
    "total_comparisons = 0\n",
    "\n",
    "for name, group in grouped:\n",
    "    if len(group) > 1:  # Only count if multiple strategies present\n",
    "        best_strategy = group.loc[group['ndcg'].idxmax(), 'strategy']\n",
    "        wins[best_strategy] += 1\n",
    "        total_comparisons += 1\n",
    "\n",
    "print(f\"\\nTotal comparisons: {total_comparisons}\")\n",
    "print(\"\\nWin counts by strategy (how many times it had the best NDCG):\")\n",
    "for strategy, count in sorted(wins.items(), key=lambda x: x[1], reverse=True):\n",
    "    win_rate = count / total_comparisons * 100 if total_comparisons > 0 else 0\n",
    "    print(f\"{strategy:20s}: {count:4d} wins ({win_rate:5.1f}%)\")\n",
    "\n",
    "# Visualize win rates\n",
    "if total_comparisons > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    strategies = sorted(wins.keys())\n",
    "    win_counts = [wins[s] for s in strategies]\n",
    "    colors_bars = [COLORS.get(s, 'gray') for s in strategies]\n",
    "    \n",
    "    ax.bar(strategies, win_counts, color=colors_bars, alpha=0.7)\n",
    "    ax.set_ylabel('Number of Wins', fontsize=LABEL_SIZE)\n",
    "    ax.set_title('Strategy Win-Rate: How Often Each Strategy Performs Best', fontsize=TITLE_SIZE)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add percentage labels on bars\n",
    "    for i, (strategy, count) in enumerate(zip(strategies, win_counts)):\n",
    "        percentage = count / total_comparisons * 100 if total_comparisons > 0 else 0\n",
    "        ax.text(i, count + total_comparisons*0.01, f'{percentage:.1f}%', \n",
    "               ha='center', va='bottom', fontsize=TICK_SIZE)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'strategy_win_rate.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best strategy by sampling rate\n",
    "print(\"=\" * 80)\n",
    "print(\"BEST STRATEGY BY SAMPLING RATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each sampling rate, find which strategy performs best on average\n",
    "rate_strategy_avg = df.groupby(['sampling_rate', 'strategy'])['ndcg'].mean().reset_index()\n",
    "\n",
    "best_by_rate = rate_strategy_avg.loc[rate_strategy_avg.groupby('sampling_rate')['ndcg'].idxmax()]\n",
    "\n",
    "print(\"\\nBest strategy at each sampling rate:\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in best_by_rate.sort_values('sampling_rate').iterrows():\n",
    "    print(f\"{row['sampling_rate']:3.0f}%: {row['strategy']:20s} (NDCG = {row['ndcg']:.4f})\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_SINGLE)\n",
    "\n",
    "for strategy in sorted(df['strategy'].unique()):\n",
    "    strategy_data = rate_strategy_avg[rate_strategy_avg['strategy'] == strategy].sort_values('sampling_rate')\n",
    "    ax.plot(strategy_data['sampling_rate'], strategy_data['ndcg'],\n",
    "           marker='o', label=strategy, color=COLORS.get(strategy, 'gray'),\n",
    "           linewidth=2, markersize=6)\n",
    "\n",
    "ax.set_xlabel('Sampling Rate (%)', fontsize=LABEL_SIZE)\n",
    "ax.set_ylabel('Average NDCG@10', fontsize=LABEL_SIZE)\n",
    "ax.set_title('Strategy Performance by Sampling Rate', fontsize=TITLE_SIZE)\n",
    "ax.legend(fontsize=TICK_SIZE)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'best_strategy_by_rate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Interactive Visualizations (Optional)\n",
    "\n",
    "Interactive plots using Plotly (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOTLY_AVAILABLE:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"INTERACTIVE VISUALIZATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Interactive line plot: NDCG by strategy\n",
    "    fig = px.line(df, x='sampling_rate', y='ndcg', color='strategy',\n",
    "                  facet_col='algorithm', facet_row='dataset',\n",
    "                  color_discrete_map=COLORS,\n",
    "                  title='Interactive NDCG@10 by Strategy',\n",
    "                  labels={'sampling_rate': 'Sampling Rate (%)', 'ndcg': 'NDCG@10'})\n",
    "    \n",
    "    fig.update_traces(mode='lines+markers')\n",
    "    fig.update_layout(height=300*len(df['dataset'].unique()))\n",
    "    fig.show()\n",
    "    \n",
    "    # Interactive scatter: Precision vs NDCG\n",
    "    fig = px.scatter(df, x='precision', y='ndcg', color='strategy',\n",
    "                    size='sampling_rate', hover_data=['dataset', 'algorithm'],\n",
    "                    color_discrete_map=COLORS,\n",
    "                    title='Interactive Scatter: Precision vs NDCG',\n",
    "                    labels={'precision': 'Precision@10', 'ndcg': 'NDCG@10'})\n",
    "    fig.show()\n",
    "    \n",
    "    # Interactive RPA plot\n",
    "    if len(df_rpa) > 0:\n",
    "        fig = px.line(df_rpa, x='sampling_rate', y='ndcg_rpa', color='strategy',\n",
    "                     color_discrete_map=COLORS,\n",
    "                     title='Interactive RPA: NDCG Performance Loss',\n",
    "                     labels={'sampling_rate': 'Sampling Rate (%)', 'ndcg_rpa': 'NDCG RPA (%)'})\n",
    "        fig.update_traces(mode='lines+markers')\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", annotation_text=\"Baseline\")\n",
    "        fig.show()\n",
    "else:\n",
    "    print(\"Plotly not available - skipping interactive visualizations\")\n",
    "    print(\"Install with: pip install plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Summary & Key Findings\n",
    "\n",
    "Synthesize insights and export recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Best overall strategy\n",
    "if len(df) > 0:\n",
    "    overall_best = df.groupby('strategy')['ndcg'].mean().idxmax()\n",
    "    overall_best_score = df.groupby('strategy')['ndcg'].mean().max()\n",
    "    \n",
    "    print(f\"\\n1. BEST OVERALL STRATEGY\")\n",
    "    print(f\"   '{overall_best}' achieves highest average NDCG@10: {overall_best_score:.4f}\")\n",
    "\n",
    "# 2. Strategy with minimal performance loss\n",
    "if len(df_rpa) > 0:\n",
    "    best_rpa_strategy = df_rpa.groupby('strategy')['ndcg_rpa'].mean().idxmax()\n",
    "    best_rpa_score = df_rpa.groupby('strategy')['ndcg_rpa'].mean().max()\n",
    "    \n",
    "    print(f\"\\n2. STRATEGY WITH MINIMAL PERFORMANCE LOSS\")\n",
    "    print(f\"   '{best_rpa_strategy}' has smallest average RPA: {best_rpa_score:.2f}%\")\n",
    "\n",
    "# 3. Critical sampling threshold\n",
    "if len(df_rpa) > 0:\n",
    "    # Find minimum sampling rate where average RPA > -10%\n",
    "    avg_rpa_by_rate = df_rpa.groupby('sampling_rate')['ndcg_rpa'].mean().sort_index()\n",
    "    critical_rates = avg_rpa_by_rate[avg_rpa_by_rate > -10.0]\n",
    "    \n",
    "    if len(critical_rates) > 0:\n",
    "        critical_threshold = critical_rates.index.min()\n",
    "        print(f\"\\n3. CRITICAL SAMPLING THRESHOLD\")\n",
    "        print(f\"   {critical_threshold:.0f}% sampling achieves <10% performance loss on average\")\n",
    "    else:\n",
    "        print(f\"\\n3. CRITICAL SAMPLING THRESHOLD\")\n",
    "        print(f\"   No sampling rate achieves <10% loss (more data needed)\")\n",
    "\n",
    "# 4. Algorithm performance\n",
    "if 'algorithm' in df.columns:\n",
    "    best_algorithm = df.groupby('algorithm')['ndcg'].mean().idxmax()\n",
    "    best_algo_score = df.groupby('algorithm')['ndcg'].mean().max()\n",
    "    \n",
    "    print(f\"\\n4. BEST ALGORITHM\")\n",
    "    print(f\"   '{best_algorithm}' achieves highest average NDCG@10: {best_algo_score:.4f}\")\n",
    "\n",
    "# 5. Temporal strategy effectiveness\n",
    "if 'temporal' in df['strategy'].unique():\n",
    "    temporal_avg = df[df['strategy'] == 'temporal']['ndcg'].mean()\n",
    "    random_avg = df[df['strategy'] == 'random']['ndcg'].mean()\n",
    "    improvement = (temporal_avg - random_avg) / random_avg * 100\n",
    "    \n",
    "    print(f\"\\n5. TEMPORAL STRATEGY EFFECTIVENESS\")\n",
    "    print(f\"   Temporal sampling: NDCG = {temporal_avg:.4f}\")\n",
    "    print(f\"   Random sampling:   NDCG = {random_avg:.4f}\")\n",
    "    print(f\"   Improvement: {improvement:+.2f}%\")\n",
    "else:\n",
    "    print(f\"\\n5. TEMPORAL STRATEGY EFFECTIVENESS\")\n",
    "    print(f\"   No temporal strategy data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations table\n",
    "print(\"=\" * 80)\n",
    "print(\"RECOMMENDATIONS TABLE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each dataset-algorithm, find:\n",
    "# 1. Best strategy at 50% sampling\n",
    "# 2. Minimum sampling rate for <10% RPA loss\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "for dataset in df['dataset'].unique():\n",
    "    for algorithm in df['algorithm'].unique():\n",
    "        subset = df[(df['dataset'] == dataset) & (df['algorithm'] == algorithm)]\n",
    "        \n",
    "        if len(subset) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Best strategy at 50%\n",
    "        subset_50 = subset[subset['sampling_rate'] == 50]\n",
    "        if len(subset_50) > 0:\n",
    "            best_strategy_50 = subset_50.loc[subset_50['ndcg'].idxmax(), 'strategy']\n",
    "            best_ndcg_50 = subset_50['ndcg'].max()\n",
    "        else:\n",
    "            best_strategy_50 = 'N/A'\n",
    "            best_ndcg_50 = np.nan\n",
    "        \n",
    "        # Minimum rate for <10% loss\n",
    "        subset_rpa = subset[(subset['sampling_rate'] != 100) & (subset['ndcg_rpa'] > -10.0)]\n",
    "        if len(subset_rpa) > 0:\n",
    "            min_rate = subset_rpa['sampling_rate'].min()\n",
    "        else:\n",
    "            min_rate = np.nan\n",
    "        \n",
    "        # Performance at 100%\n",
    "        subset_100 = subset[subset['sampling_rate'] == 100]\n",
    "        if len(subset_100) > 0:\n",
    "            ndcg_100 = subset_100['ndcg'].mean()\n",
    "        else:\n",
    "            ndcg_100 = np.nan\n",
    "        \n",
    "        recommendations.append({\n",
    "            'dataset': dataset,\n",
    "            'algorithm': algorithm,\n",
    "            'best_strategy_at_50pct': best_strategy_50,\n",
    "            'ndcg_at_50pct': best_ndcg_50,\n",
    "            'min_rate_for_10pct_loss': min_rate,\n",
    "            'baseline_ndcg_100pct': ndcg_100\n",
    "        })\n",
    "\n",
    "recommendations_df = pd.DataFrame(recommendations)\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "display(recommendations_df)\n",
    "\n",
    "# Export to CSV\n",
    "recommendations_path = RESULTS_DIR / 'recommendations.csv'\n",
    "recommendations_df.to_csv(recommendations_path, index=False)\n",
    "print(f\"\\nExported recommendations to: {recommendations_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness report\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA COMPLETENESS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Expected experiments\n",
    "expected_datasets = 12\n",
    "expected_algorithms = 3\n",
    "expected_strategies = 4\n",
    "expected_rates = 10\n",
    "expected_total = expected_datasets * expected_algorithms * expected_strategies * expected_rates\n",
    "\n",
    "actual_total = len(df)\n",
    "completion_pct = actual_total / expected_total * 100\n",
    "\n",
    "print(f\"\\nData Completeness:\")\n",
    "print(f\"  Expected experiments: {expected_total}\")\n",
    "print(f\"  Actual experiments:   {actual_total}\")\n",
    "print(f\"  Completion:           {completion_pct:.1f}%\")\n",
    "print(f\"  Missing:              {expected_total - actual_total}\")\n",
    "\n",
    "# Missing by dimension\n",
    "print(f\"\\nAvailable dimensions:\")\n",
    "print(f\"  Datasets:   {df['dataset'].nunique()}/{expected_datasets}\")\n",
    "print(f\"  Algorithms: {df['algorithm'].nunique()}/{expected_algorithms}\")\n",
    "print(f\"  Strategies: {df['strategy'].nunique()}/{expected_strategies}\")\n",
    "print(f\"  Rates:      {df['sampling_rate'].nunique()}/{expected_rates}\")\n",
    "\n",
    "# Missing datasets\n",
    "all_expected_datasets = ['Amazon_Health_and_Personal_Care', 'Amazon_Grocery_and_Gourmet_Food',\n",
    "                        'book-crossing', 'lastfm', 'ModCloth', 'pinterest', 'RateBeer',\n",
    "                        'steam', 'yelp2022', 'jester', 'Behance', 'mind']\n",
    "missing_datasets = set(all_expected_datasets) - set(df['dataset'].unique())\n",
    "\n",
    "if missing_datasets:\n",
    "    print(f\"\\nMissing datasets ({len(missing_datasets)}):\")\n",
    "    for dataset in sorted(missing_datasets):\n",
    "        print(f\"  - {dataset}\")\n",
    "\n",
    "# Missing strategies\n",
    "all_expected_strategies = ['difficult', 'random', 'difficult_inverse', 'temporal']\n",
    "missing_strategies = set(all_expected_strategies) - set(df['strategy'].unique())\n",
    "\n",
    "if missing_strategies:\n",
    "    print(f\"\\nMissing strategies ({len(missing_strategies)}):\")\n",
    "    for strategy in sorted(missing_strategies):\n",
    "        print(f\"  - {strategy}\")\n",
    "\n",
    "# Suggestions\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"SUGGESTIONS FOR ADDITIONAL EXPERIMENTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if missing_datasets:\n",
    "    print(f\"\\n1. Run experiments on {len(missing_datasets)} missing datasets\")\n",
    "\n",
    "if missing_strategies:\n",
    "    print(f\"\\n2. Implement and test {len(missing_strategies)} missing strategies\")\n",
    "\n",
    "# Incomplete dataset-algorithm combinations\n",
    "incomplete_combos = []\n",
    "for dataset in df['dataset'].unique():\n",
    "    for algorithm in df['algorithm'].unique():\n",
    "        subset = df[(df['dataset'] == dataset) & (df['algorithm'] == algorithm)]\n",
    "        expected_for_combo = expected_strategies * expected_rates\n",
    "        if len(subset) < expected_for_combo:\n",
    "            incomplete_combos.append((dataset, algorithm, len(subset), expected_for_combo))\n",
    "\n",
    "if incomplete_combos:\n",
    "    print(f\"\\n3. Complete {len(incomplete_combos)} partially-finished dataset-algorithm combinations:\")\n",
    "    for dataset, algorithm, actual, expected in incomplete_combos[:5]:\n",
    "        print(f\"   - {dataset} - {algorithm}: {actual}/{expected} experiments\")\n",
    "    if len(incomplete_combos) > 5:\n",
    "        print(f\"   ... and {len(incomplete_combos) - 5} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook provides comprehensive analysis of the sampling experiment results. Key outputs:\n",
    "\n",
    "1. **Individual plots**: Metric and RPA plots for each dataset-algorithm combination\n",
    "2. **Aggregated analysis**: Strategy comparison, heatmaps, and RPA trends\n",
    "3. **Statistical insights**: Distributions, correlations, efficiency analysis\n",
    "4. **Comparative analysis**: Algorithm comparison, dataset rankings, strategy win-rates\n",
    "5. **Recommendations**: Exported to `results/recommendations.csv`\n",
    "6. **Data quality report**: Completeness analysis and suggestions\n",
    "\n",
    "All plots are saved to the `plots/` directory at 300 DPI for publication quality.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Review the recommendations table for best strategies per dataset-algorithm\n",
    "2. Check the data completeness report for missing experiments\n",
    "3. Run additional experiments as suggested\n",
    "4. Re-run this notebook after collecting more data for updated analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
